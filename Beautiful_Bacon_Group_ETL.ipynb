{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Requirements:\n",
    "US Bureau of Labor Statistic API Key in config.py\n",
    "Postgres credentials in config.py\n",
    "\n",
    "Sample Code Source:\n",
    "https://www.bls.gov/developers/api_python.htm#python2\n",
    "\n",
    "Data website:\n",
    "https://www.kroger.com/p/smithfield-thick-cut-naturally-hickory-smoked-bacon/0007080004125\n",
    "https://data.bls.gov/timeseries/APU0000704111\n",
    "'''\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import datetime as dt\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine, func, inspect\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from config import bls_api_key, username, passphrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kroger Smithfield Thick Cut Naturally Hickory Smoked Bacon 16oz pricing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.50\n"
     ]
    }
   ],
   "source": [
    "# Kroger Pricing ETL\n",
    "\n",
    "# Splinter browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# Read url\n",
    "url = 'https://www.kroger.com/p/smithfield-thick-cut-naturally-hickory-smoked-bacon/0007080004125'\n",
    "browser.visit(url)\n",
    "\n",
    "# Browse and look for confirm and click thru\n",
    "browser.find_by_text('Confirm').first.click()\n",
    "\n",
    "# Scrape website and look for price of bacon\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "quotes = soup.find_all('mark',  class_=\"kds-Price-promotional\")\n",
    "\n",
    "# Once price is find, split and just collect the price\n",
    "price=str(quotes[0]).split('>')[1].split('<')[0]\n",
    "price=price.replace(\"$\",\"\")\n",
    "print(price)\n",
    "\n",
    "# Find the date\n",
    "my_date=dt.date.today()\n",
    "\n",
    "# Store the price and date into a dictionary\n",
    "data_dict={\"date\":[my_date],\n",
    "          \"price\":[price]}\n",
    "\n",
    "# Print out data_dict\n",
    "data_dict\n",
    "\n",
    "# Convert into a DataFrame\n",
    "data_pd=pd.DataFrame(data_dict)\n",
    "\n",
    "# Show DataFrame\n",
    "data_pd\n",
    "\n",
    "# Connect to Postgres\n",
    "rds_connection_string = f\"{username}:{passphrase}@localhost:5432/bacon_db\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')\n",
    "\n",
    "# Create table to PG Admin\n",
    "data_pd.to_sql(name='kroger_price', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# Close the brower\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Bureau of Labor Statistics Bacon CPI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "now_year = dt.date.today().year\n",
    "\n",
    "def download_bls_api(startyear =  now_year - 1, endyear = now_year):\n",
    "    \n",
    "    '''Default to since last year'''\n",
    "\n",
    "    # Define variables\n",
    "    series_id = 'APU0000704111'\n",
    "    \n",
    "    # Convert years to string\n",
    "    startyear = str(startyear)\n",
    "    endyear   = str(endyear)\n",
    "\n",
    "    # Pulling API Data from US Bureau of Labor Statistics\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    data    = json.dumps({\"seriesid\": [series_id], \"startyear\"  : startyear, \"endyear\" : endyear, \"registrationkey\": bls_api_key})\n",
    "    p       = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data = data, headers = headers)\n",
    "    json_data = json.loads(p.text)\n",
    "    \n",
    "    # Print Status\n",
    "    print(json_data[\"status\"])\n",
    "    \n",
    "    # Print API return message if it's not empty\n",
    "    if json_data['message']:\n",
    "        print(json_data['message'])\n",
    "        \n",
    "    return json_data\n",
    "\n",
    "def transform_bls_data(json_data):\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    data_dict = {\n",
    "        'year_month'  : [],\n",
    "        'value' : [],\n",
    "    }\n",
    "\n",
    "    for item in json_data['Results']['series'][0]['data']:\n",
    "\n",
    "        year_month  = item['year'] + item['period'].replace('M', '')\n",
    "        value  = float(item['value'])\n",
    "        \n",
    "        data_dict['year_month'].append(year_month)\n",
    "        data_dict['value'].append(value)\n",
    "\n",
    "    data_pd = pd.DataFrame(data_dict)\n",
    "\n",
    "    return data_pd\n",
    "\n",
    "def store_cpi_data_to_db(data_pd):\n",
    "\n",
    "    # Connect to Postgres\n",
    "    rds_connection_string = f\"{username}:{passphrase}@localhost:5432/bacon_db\"\n",
    "    engine = create_engine(f'postgresql://{rds_connection_string}')\n",
    "\n",
    "    # Pull the last 24 data points from the database\n",
    "    try:\n",
    "        last_24m = pd.read_sql_query('SELECT * FROM bacon_cpi LIMIT 24', con=engine)\n",
    "    except:\n",
    "        # If the table bacon_cpi doesn't exsit in the database. Create one.\n",
    "        data_pd.to_sql(name='bacon_cpi', con = engine, if_exists='append', index = False)\n",
    "        \n",
    "        print('A new table bacon_cpi has been created in the database bacon_db.')\n",
    "        return\n",
    "    \n",
    "    # Store only the new data to the database\n",
    "    for year_month in data_pd.year_month:\n",
    "        if year_month not in last_24m.year_month.values:\n",
    "        \n",
    "            new_data = data_pd.loc[data_pd.year_month == year_month].copy()\n",
    "        \n",
    "            # Load Bacon CPI Data to Postgres\n",
    "            new_data.to_sql(name='bacon_cpi', con = engine, if_exists='append', index = False)\n",
    "        \n",
    "            print(year_month, 'cpi data has been loaded to the database bacon_db.')\n",
    "            \n",
    "    return\n",
    "\n",
    "# Extract Data\n",
    "json_data = download_bls_api()\n",
    "\n",
    "# Transform data\n",
    "data_pd = transform_bls_data(json_data)\n",
    "\n",
    "# Load data\n",
    "store_cpi_data_to_db(data_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lean Hogs futures from Investing.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Change PCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>56.85</td>\n",
       "      <td>56.45</td>\n",
       "      <td>56.92</td>\n",
       "      <td>55.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>56.92</td>\n",
       "      <td>58.67</td>\n",
       "      <td>58.80</td>\n",
       "      <td>56.65</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>-0.0540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>60.17</td>\n",
       "      <td>60.10</td>\n",
       "      <td>62.00</td>\n",
       "      <td>60.05</td>\n",
       "      <td>6530.0</td>\n",
       "      <td>-0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>60.50</td>\n",
       "      <td>59.30</td>\n",
       "      <td>61.30</td>\n",
       "      <td>58.80</td>\n",
       "      <td>6860.0</td>\n",
       "      <td>0.0293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>58.78</td>\n",
       "      <td>59.03</td>\n",
       "      <td>59.72</td>\n",
       "      <td>58.55</td>\n",
       "      <td>5040.0</td>\n",
       "      <td>-0.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>59.35</td>\n",
       "      <td>57.03</td>\n",
       "      <td>59.42</td>\n",
       "      <td>56.95</td>\n",
       "      <td>8180.0</td>\n",
       "      <td>0.0435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>56.88</td>\n",
       "      <td>56.05</td>\n",
       "      <td>57.05</td>\n",
       "      <td>55.75</td>\n",
       "      <td>5810.0</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>56.65</td>\n",
       "      <td>57.60</td>\n",
       "      <td>58.65</td>\n",
       "      <td>56.55</td>\n",
       "      <td>6190.0</td>\n",
       "      <td>-0.0173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>57.65</td>\n",
       "      <td>58.50</td>\n",
       "      <td>58.80</td>\n",
       "      <td>57.10</td>\n",
       "      <td>9450.0</td>\n",
       "      <td>-0.0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>57.88</td>\n",
       "      <td>58.22</td>\n",
       "      <td>59.40</td>\n",
       "      <td>57.75</td>\n",
       "      <td>11610.0</td>\n",
       "      <td>-0.1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>68.68</td>\n",
       "      <td>68.25</td>\n",
       "      <td>68.75</td>\n",
       "      <td>67.90</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>68.00</td>\n",
       "      <td>67.50</td>\n",
       "      <td>68.28</td>\n",
       "      <td>67.25</td>\n",
       "      <td>710.0</td>\n",
       "      <td>-0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>68.03</td>\n",
       "      <td>67.57</td>\n",
       "      <td>68.07</td>\n",
       "      <td>67.32</td>\n",
       "      <td>460.0</td>\n",
       "      <td>0.0256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>66.32</td>\n",
       "      <td>67.10</td>\n",
       "      <td>67.75</td>\n",
       "      <td>66.22</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>-0.0145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>67.30</td>\n",
       "      <td>68.25</td>\n",
       "      <td>68.70</td>\n",
       "      <td>67.20</td>\n",
       "      <td>490.0</td>\n",
       "      <td>-0.0218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>68.80</td>\n",
       "      <td>67.93</td>\n",
       "      <td>68.95</td>\n",
       "      <td>65.55</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>68.10</td>\n",
       "      <td>66.97</td>\n",
       "      <td>68.20</td>\n",
       "      <td>66.50</td>\n",
       "      <td>770.0</td>\n",
       "      <td>0.0295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>66.15</td>\n",
       "      <td>66.50</td>\n",
       "      <td>67.40</td>\n",
       "      <td>65.00</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>-0.0233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>67.72</td>\n",
       "      <td>65.88</td>\n",
       "      <td>68.25</td>\n",
       "      <td>65.43</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>0.0771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>62.88</td>\n",
       "      <td>60.92</td>\n",
       "      <td>62.88</td>\n",
       "      <td>60.92</td>\n",
       "      <td>660.0</td>\n",
       "      <td>0.0634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>59.13</td>\n",
       "      <td>57.42</td>\n",
       "      <td>59.47</td>\n",
       "      <td>57.40</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0.0506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Price   Open   High    Low   Volume  Change PCT\n",
       "0  2020-05-29  56.85  56.45  56.92  55.92      0.0     -0.0013\n",
       "1  2020-05-28  56.92  58.67  58.80  56.65   7600.0     -0.0540\n",
       "2  2020-05-27  60.17  60.10  62.00  60.05   6530.0     -0.0054\n",
       "3  2020-05-26  60.50  59.30  61.30  58.80   6860.0      0.0293\n",
       "4  2020-05-22  58.78  59.03  59.72  58.55   5040.0     -0.0097\n",
       "5  2020-05-21  59.35  57.03  59.42  56.95   8180.0      0.0435\n",
       "6  2020-05-20  56.88  56.05  57.05  55.75   5810.0      0.0040\n",
       "7  2020-05-19  56.65  57.60  58.65  56.55   6190.0     -0.0173\n",
       "8  2020-05-18  57.65  58.50  58.80  57.10   9450.0     -0.0039\n",
       "9  2020-05-15  57.88  58.22  59.40  57.75  11610.0     -0.1573\n",
       "10 2020-05-14  68.68  68.25  68.75  67.90    240.0      0.0099\n",
       "11 2020-05-13  68.00  67.50  68.28  67.25    710.0     -0.0004\n",
       "12 2020-05-12  68.03  67.57  68.07  67.32    460.0      0.0256\n",
       "13 2020-05-11  66.32  67.10  67.75  66.22   1160.0     -0.0145\n",
       "14 2020-05-08  67.30  68.25  68.70  67.20    490.0     -0.0218\n",
       "15 2020-05-07  68.80  67.93  68.95  65.55    800.0      0.0103\n",
       "16 2020-05-06  68.10  66.97  68.20  66.50    770.0      0.0295\n",
       "17 2020-05-05  66.15  66.50  67.40  65.00   1300.0     -0.0233\n",
       "18 2020-05-04  67.72  65.88  68.25  65.43   1270.0      0.0771\n",
       "19 2020-05-01  62.88  60.92  62.88  60.92    660.0      0.0634\n",
       "20 2020-04-30  59.13  57.42  59.47  57.40   1010.0      0.0506"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lean_hog_data_pull():\n",
    "    # Creating the browser to scrape with\n",
    "    executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    \n",
    "    # Giving the web path to the site we are scraping\n",
    "    url = 'https://www.investing.com/commodities/lean-hogs-historical-data'\n",
    "    browser.visit(url)\n",
    "    \n",
    "    # Iterate through all pages\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Finding the correct table, there are multiple tables on the page, ours is the only with \"Open\" in the table\n",
    "    texts = soup.find_all(\"table\")\n",
    "    for item in texts:\n",
    "        if \"Open\" in item.get_text():\n",
    "            tabletext = item.get_text()\n",
    "            \n",
    "    # Cleaning up some of the text to prepare for a list of lists\n",
    "    tabletext = tabletext.replace(\"\\n\", \"|\")\n",
    "    tabletext = tabletext.replace(\"|-\", \"|0.00K\")\n",
    "    tabletext = tabletext.replace(\"Vol.\", \"Volume|\")\n",
    "    tabletext = tabletext.replace(\"K\", \"K|\")\n",
    "    tabletext = tabletext.replace(\"%\", \"PCT\")\n",
    "    tabletext = tabletext.replace(\" Change\", \"Change\")\n",
    "    \n",
    "    # Splitting the data to create the first list; cleaning it up a bit\n",
    "    tablelist = tabletext.split(\"|||\")\n",
    "    cleanerlist = []\n",
    "    for item in tablelist:\n",
    "        if item != \"\":\n",
    "            cleanerlist.append(item.replace(\"||\",\"\"))\n",
    "            \n",
    "    # Creating a list of lists\n",
    "    listolist = []\n",
    "    for item in tablelist:\n",
    "        listolist.append(item.split(\"|\"))\n",
    "    \n",
    "    #Removing blank lists\n",
    "    listolist = [x for x in listolist if x != ['']]\n",
    "    \n",
    "    #Creating a clean list of lists where each list has the blanks ('') removed\n",
    "    clistolist = []\n",
    "    for item in listolist:\n",
    "        clistolist.append(list(filter(None,item)))\n",
    "    for item in clistolist:\n",
    "        for itemtwo in item:\n",
    "            itemtwo = itemtwo.strip()\n",
    "            \n",
    "    #Turning the clean list of lists into a dataframe\n",
    "    df = pd.DataFrame(clistolist[1:], columns = clistolist[0])\n",
    "    \n",
    "    #Cleaning up the dataframe\n",
    "    df['Volume'] = df['Volume'].str.replace('K','')\n",
    "    df['Date'] = df['Date'].str.replace(\", \",\"-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Jan \",\"01-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Feb \",\"02-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Mar \",\"03-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Apr \",\"04-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"May \",\"05-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Jun \",\"06-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Jul \",\"07-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Aug \",\"08-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Sep \",\"09-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Oct \",\"10-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Nov \",\"11-\")\n",
    "    df['Date'] = df['Date'].str.replace(\"Dec \",\"12-\")\n",
    "    df['Change PCT'] = df['Change PCT'].str.replace(\"PCT\",\"\")\n",
    "    df['Change PCT'] = pd.to_numeric(df['Change PCT']) / 100\n",
    "    df['Volume'] = pd.to_numeric(df['Volume']) * 1000\n",
    "    df['Price'] = pd.to_numeric(df['Price'])\n",
    "    df['Open'] = pd.to_numeric(df['Open'])\n",
    "    df['High'] = pd.to_numeric(df['High'])\n",
    "    df['Low'] = pd.to_numeric(df['Low'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Connect to Postgres\n",
    "    rds_connection_string = f\"postgres:postgres@localhost:5432/bacon_db\"\n",
    "    engine = create_engine(f'postgresql://{rds_connection_string}')\n",
    "    \n",
    "    # Pulling the historical data if it exists\n",
    "    try:\n",
    "        olddf = pd.read_sql_table(\"lean_hog_commodity\", con=engine)\n",
    "        fulldf = olddf.append(df,ignore_index=True)\n",
    "    except:\n",
    "        fulldf = df\n",
    "    fulldf = fulldf.drop_duplicates('Date',keep='last')\n",
    "    \n",
    "    # Load Lean Hog Commodity to Postgres\n",
    "    fulldf.to_sql(name='lean_hog_commodity', con = engine, if_exists='replace', index = False)\n",
    "    \n",
    "    # Closing out the browser\n",
    "    browser.quit()\n",
    "    return fulldf\n",
    "\n",
    "lean_hog_data_pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "via2",
   "language": "python",
   "name": "via2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
